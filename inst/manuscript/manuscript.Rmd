---
documentclass: jss
author:
    # use this syntax to add text on several lines
    # To add another line, use \AND at the end of the previous one as above
    # use a different affiliation in adress field (differently formated here)
  - name: Michael Dumelle
    orcid: 0000-0002-3393-5529
    affiliation: |
      | United States
      | Environmental Protection Agency
    address: |
      | 200 SW 35th St
      | Corvallis, OR, 97330
    email: \email{Dumelle.Michael@epa.gov}
  - name: Jay M. Ver Hoef
    orcid: 0000-0003-4302-6895
    affiliation: |
      | Alaska Fisheries
      | Science Center
  - name: Matt Higham
    orcid: 0009-0006-4217-625X
    affiliation: |
      | St. Lawrence University
title:
  # If you use tex in the formatted title, also supply version without
  # For running headers, if needed
  formatted: "Spatial Generalized Linear Models in \\proglang{R} Using \\pkg{spmodel}"
  plain:     "Spatial Generalized Linear Models in R Using spmodel"
  short:     "Spatial Generalized Linear Models in \\proglang{R} Using \\pkg{spmodel}"
abstract: |
  Generalized linear models (GLMs) describe a non-normal response variable that may be binary, count, skewed, or a proportion. Typically, observations in a GLM are assumed independent of one another. For spatial data, this independence assumption is impractical, as nearby locations tend to be more similar than locations far apart. The \pkg{spmodel} \proglang{R} package provides tools to fit GLMs that incorporate spatial correlation (i.e., spatial generalized linear models, or SPGLMs). SPGLMs are fit in \pkg{spmodel} using a novel application of the Laplace approximation via \code{spglm()} for point-referenced data or \code{spgautor()} for areal (i.e., lattice), data. \code{spglm()} and \code{spgautor()} closely resemble [glm]{.fct} from base \proglang{R} but include arguments that control the spatial correlation structure. \pkg{spmodel} has many helper functions for model inspection and diagnostics, some of which leverage other \proglang{R} packages like [broom]{.pkg} and [emmeans]{.pkg}. \pkg{spmodel} has tools to make predictions of the latent spatial-mean process at unobserved locations. \pkg{spmodel} also provides many advanced features like accommodating geometric anisotropy and nonspatial random effects, simulating spatially autocorrelated data, and more. Here we use \pkg{spmodel} to illustrate the modeling of binary, count, skewed and proportion response variables from several point-referenced and areal data sets. 
keywords:
  # at least one keyword must be supplied
  formatted: [autoregressive model, geostatistical model, spatial covariance, spatial correlation]
  plain:     [autoregressive model, geostatistical model, spatial covariance, spatial correlation]
preamble: |
  \usepackage{amsmath,amsfonts,amssymb}
  \usepackage{bm, bbm}
  \usepackage{lineno}
  \usepackage{caption, subcaption}
output: rticles::jss_article
editor_options: 
  chunk_output_type: console
---

```{r, setup, include=FALSE}
options(prompt = 'R> ', continue = '+ ')
library(spmodel)
library(ggplot2)
library(dplyr)
#library(emmeans)
#library(car)
library(here)
fig_path <- here("inst", "manuscript", "figures")
```

\newpage

# Introduction {#sec-intro}

In practice, non-Gaussian data are ubiquitous. Non-Gaussian that belong to an exponential family data can be naturally modeled using a generalized linear model (GLM) regression framework [@nelder1972generalized; @mccullagh1989generalized; @myers2012generalized; @faraway2016extending]. In a GLM, an $n \times 1$ response variable $\mathbf{y}$ belongs to a statistical distribution (e.g., Poisson, Binomial) with some mean and variance. Often, the analysis goal is to study the impact of a linear function of several explanatory variables on $\text{y}$ through a GLM. In this context, the latent (i.e., unobserved) mean of $\mathbf{y}$, $\boldsymbol{\mu}$, is linked to these explanatory variables via a link function:
\begin{equation}\label{eq-glm}
f(\boldsymbol{\mu}|\mathbf{X}, \boldsymbol{\beta}) \equiv \mathbf{w} = \mathbf{X} \boldsymbol{\beta},
\end{equation}
where for a sample size $n$, $f(\cdot)$ is a link function that connects $\boldsymbol{\mu}$ to $\mathbf{w}$, $\mathbf{X}$ is the $n \times p$ design matrix of explanatory variables, and $\boldsymbol{\beta}$ is the $p \times 1$ vector of fixed effects. While the mean is typically constrained in some way (e.g., between zero and one if a probability), the link function generally makes $\mathbf{w}$ is unconstrained. Common link functions inlude the log odds (i.e., logit) link for binary and proportion data and the log link count and skewed data. Equation$~$\ref{eq-glm} can also be written in terms of the inverse link function, $f^{-1}(\cdot)$:
\begin{equation}\label{eq-glm2}
\boldsymbol{\mu}|\mathbf{X}, \boldsymbol{\beta} \equiv f^{-1}(\mathbf{w}) = f^{-1}(\mathbf{X} \boldsymbol{\beta}),
\end{equation}

The GLM fixed effects ($\boldsymbol{\beta}$) are typically estimated via maximum likelihood [@chambers1992S]. It is often convenient to compute the maximum likelihood estimates using the iteratively reweighted least squares (IRWLS) algorithm [@wood2017generalized], which is the approach used by the  \code{glm()} function in the \proglang{R} programming language [@rcore2024]. GLMs add an additional layer of complexity compared to linear regression models, as the left-hand size of Equation$~$\ref{eq-glm} is a function of the mean of $\mathbf{y}$ rather than $\mathbf{y}$ itself (as in linear regression models).

The standard GLM assumes the elements of $\mathbf{y}$ are independent. This independence assumption is typically impractical for spatial data. In spatial data, nearby observations tend to be more similar than distant observations [@tobler1970computer], leading to positive spatial covariance among observations. The consequences of ignoring spatial covariance in statistical models for spatial data can be severe and include imprecise parameter estimates as well as misleading standard errors that inflate Type-I error rates and decrease power [@zimmerman2024spatial].

An approach for handling spatial data using a GLM is to assume $\mathbf{w}$ has spatial covariance. This is achieved by adding to Equation$~$\ref{eq-glm} two random effects, $\boldsymbol{\tau}$ and $\boldsymbol{\epsilon}$. The random effect $\boldsymbol{\tau}$ is an $n \times 1$ column vector of spatially dependent random errors. We assume that $\text{E}(\boldsymbol{\tau}) = \boldsymbol{0}$ and $\text{Cov}(\boldsymbol{\tau}) = \sigma^2_\tau \mathbf{R}$, where $\text{E}(\cdot)$ and $\text{Cov}(\cdot)$ denote expectation and covariance, respectively. The variance parameter $\sigma^2_\tau$ controls the magnitude of spatial covariance and is often called a partial sill, while the matrix $\mathbf{R}$ is an $n \times n$ spatial correlation matrix that depends on a range parameter which controls the distance-decay rate of the spatial correlation. One example of a spatial covariance matrix is the "exponential", which is given by
\begin{equation}\label{eq-spcov-exp}
  \text{Cov}(\boldsymbol{\tau}) = \sigma^2_{de} \exp(-\mathbf{H}/\phi),
\end{equation}
where $\mathbf{H}$ is a matrix of pairwise distances among the elements of $\mathbf{y}$ and $\phi$ is a range parameter. From Equation$~$\ref{eq-spcov-exp}, as the distance between two elements of $\mathbf{y}$ increases, the spatial covariance decreases, which reflects intuition. Moreover, as the range parameter, $\phi$, increases, the strength of spatial dependence increases (Figure$~$\ref{fig-range}). The random effect $\boldsymbol{\epsilon}$ is an $n \times 1$ column vector of independent random errors. We assume that $\text{E}(\boldsymbol{\epsilon}) = \boldsymbol{0}$ and $\text{Cov}(\boldsymbol{\tau}) = \sigma^2_\epsilon \mathbf{I}$, where $\mathbf{I}$ is an $n \times n$ identity matrix. The variance parameter $\sigma^2_\epsilon$ controls the magnitude of nonspatial variability (i.e., fine-scale variation) and is often called a nugget. 

\begin{figure}
\centering
\includegraphics[width = 0.7\linewidth]{figures/figure-01.png}
\caption{An exponential spatial correlation function with varying range parameters.}
\label{fig-range}
\end{figure}

Through inclusion of $\boldsymbol{\tau}$ and $\boldsymbol{\epsilon}$, the spatial GLM (SPGLM) can be written as
\begin{equation}\label{eq-spglm}
f(\boldsymbol{\mu}|\mathbf{X}, \boldsymbol{\beta}, \boldsymbol{\tau}, \boldsymbol{\epsilon}) \equiv \mathbf{w} = \mathbf{X} \boldsymbol{\beta} + \boldsymbol{\tau} + \boldsymbol{\epsilon}.
\end{equation}
Often in spatial statistics, quantities are explicitly referenced with respect to $\mathbf{s}$, a vector of coordinates indexing the observation [@cressie1993statistics]. For example, $\mathbf{y}$ and $\mathbf{X}$ may instead be written $\mathbf{y}(\mathbf{s})$ and $\mathbf{X}$, respectively. We acknowledge the utility of this nomenclature but drop the explicit dependence on $\mathbf{s}$ for simplicity of notation.
Assuming independence among $\boldsymbol{\tau}$ and $\boldsymbol{\epsilon}$, it follows that 
\begin{equation}\label{eq-spcov}
 \text{Cov}(\boldsymbol{\tau} + \boldsymbol{\epsilon}) = \text{Cov}(\boldsymbol{\tau}) + \text{Cov}(\boldsymbol{\epsilon}) = \sigma^2_{\tau}\mathbf{R} + \sigma^2_{\epsilon} \mathbf{I}.
\end{equation}
To better align with intuition, we henceforth $\sigma^2_{\tau}$ as $\sigma^2_{de}$ (for spatially dependent error variance) and $\sigma^2_{\epsilon}$ as $\sigma^2_{ie}$ (for independent error variance). The parameters $\sigma^2_{de}$, $\sigma^2_{ie}$, the range parameter $\phi$ in $\mathbf{R}$, and any other parameters in $\mathbf{R}$ compose $\boldsymbol{\theta}$, the covariance parameter vector. 

Fitting and using SPGLMs is challenging both conceptually and computationally [@bolker2009generalized]. Recently, however, there have been numerous, significant advances in \proglang{R} software that have made these models more accessible to practitioners. The \pkg{brms} [@burkner2017brms], \pkg{carBayes} [@lee2013carbayes], \pkg{ngspatial} [@hughes2020ngspatial], \pkg{R-INLA} [@lindgren2015bayesian] and \pkg{inlabru} [@bachl2019inlabru], \pkg{spBayes} [@finley2007spbayes], \pkg{spOccupancy} [@doser2022spoccupancy], \pkg{spAbundance} [@doser2024spabundance], and \pkg{spNNGP} [@finley2002spnngp] packages take a Bayesian approach, either directly sampling from posterior distributions of parameters (e.g., using MCMC) or approximating them. A benefit of Bayesian approaches is that prior information can be incorporated and uncertainty quantification of parameter estimates is straightforward. However, Bayesian approaches, especially those using MCMC, can be computationally expensive. In order to reduce computation time, many of these packages work with the precision matrix instead of the covariance matrix so that computationally expensive matrix inversion is not required. For example, \pkg{R-INLA} uses the precision matrix and tends to be very fast. Working with precision matrices, however, can be more restrictive and less intuitive than working directly with the covariance matrix. The [FRK]{.pkg} [@sainsbury2024modeling], \pkg{glmmTMB} [@brooks2017glmmtmb], \pkg{hglm} [@ronnegard2010hglm], \pkg{mgcv} [@wood2017generalized], and \pkg{spaMM} [@rousset2014spamm] packages directly use Laplace, quasi-likelihood, or reduced-rank approaches to estimate parameters. These direct approaches tend to be computationally efficient, as they don't rely on MCMC sampling. In contrast to the Bayesian approach, a drawback of these direct approaches is that prior information cannot be formally incorporated and covariance parameter uncertainty is more challenging to quantify. The \pkg{sdmTMB} [@anderson2024sdmtmb] package combines elements of \pkg{R-INLA}, \pkg{glmmTMB}, and properties of Gaussian Markov random fields to fit a wide variety of SPGLMs, and \pkg{tinyVAST} [@thorson2025tinyVAST] extends some of these models to multivariate or (dynamic) structural equation models.

@ver2024marginal proposed a novel approach to fitting SPGLMs that leverages the Laplace approximation while marginalizing over both the latent $\mathbf{w}$ and the fixed effects ($\boldsymbol{\beta}$) and accommodating spatial covariance. @ver2024marginal showed that this approach performed efficiently in a variety of simulation settings, generally having appropriate confidence interval coverage for the fixed effects and prediction interval coverage for new $\mathbf{w}$. The approach performed similarly to the Bayesian SPGLM approach in \pkg{spBayes} and the automatic differentiation SPGLM approach in \pkg{glmmTMB} but was much faster. At small sample sizes, the approach outperformed the approximate Bayesian SPGLM approach in \pkg{R-INLA} and had similar computational times. For moderate sample sizes, it performed similarly to \pkg{R-INLA}, though \pkg{R-INLA} was faster. This novel approach is particularly attractive for two reasons. First, it is general enough that can be applied to any covariance structure (not just spatial). Second, after estimating the covariance parameters, analytical solutions exist for the fixed effects (and their standard errors) as well as predictions of the latent $\mathbf{w}$ at new locations (and their standard errors). The \pkg{spmodel} \proglang{R} package [@dumelle2023spmodel] recently provided full support for the methods in @ver2024marginal applied to binary, count, skewed, and proportion data for over 20 different spatial covariance types.

The \pkg{spmodel} \proglang{R} package [@dumelle2023spmodel] recently provided a full set of modeling tools for SPGLMs fit using the methods described in @ver2024marginal. These modeling tools are approachable and mirror the familiar \code{glm()} syntax from base-\proglang{R}, making the transition from GLMs to SPGLMs relatively seamless. The \code{spglm()} function fits SPGLMs for point-referenced data (e.g., x-coordinates and y-coordinates representing point locations in a field), while the \code{spgautor()} function fits SPGLMs for areal data (e.g., polygon boundaries representing geographic subsets of a region). \pkg{spmodel} supports the binomial distribution for binary data, Poisson and negative binomial distributions for count data, Gamma and inverse Gaussian distributions for skewed data, and the beta distribution for proportion data. There are 20 different spatial covariance structures available including the exponential, Gaussian, and spherical for point-referenced data (Figure$~$\ref{fig-type}) and the conditional autoregressive, and simultaneous autoregressive structures for areal data. \pkg{spmodel} provides tools for commonly used model summaries, visualizations, and diagnostics (e.g., Cook's distance) using standard \proglang{R} helper functions like \code{summary()}, \code{plot()}, and \code{cooks.distance()}. \pkg{spmodel} also provides tools to predict $\mathbf{w}$ at new locations and quantify uncertainty in those prediction using \code{predict()}. This core functionality, combined with several advanced features we describe throughout the manuscript, enables \pkg{spmodel} to provide some novel and important capabilities previously missing from the existing SPGLM ecosystem in \proglang{R}.

\begin{figure}
\centering
\includegraphics[width = 0.7\linewidth]{figures/figure-02.png}
\caption{Exponential, Gaussian, and spherical spatial correlation functions all with range parameters equal to 0.5.}
\label{fig-type}
\end{figure}

\pkg{spmodel} (version 0.11.0) is arguably most similar to \pkg{sdmTMB} (version 0.7.4) in terms of scope and feel. Both packages use similar syntax as \code{glm()}, accommodate flexible \code{formula} arguments (e.g., offsets, splines), handle spatial covariance that decays at different rates in different directions (i.e., geometric anisotropy), incorporate nonspatial random effects, support other \proglang{R} packages for modeling like \pkg{broom} [@robinson2021broom; @kuhn2022tidy], \pkg{emmeans} [@lenth2024emmeans], and \pkg{car} [@fox2019car], and have tools for model summaries, prediction, and simulating data. There are some notable differences between the two packages, however. \pkg{sdmTMB} supports several additional GLM distributions like the Tweedie, supports Hurdle models, and can incorporate prior information through Bayesian applications. \pkg{sdmTMB} also provides tools for working with temporal data and spatiotemporal data and provides enhanced visualizations of the model's marginal effects. \pkg{sdmTMB} does require a preprocessing step of constructing a mesh for the stochastic partial differential equation approach, and the density of the mesh can affect model results and computational complexity. On the other hand, \pkg{spmodel} does not require the construction of a mesh prior to modeling. \pkg{spmodel} supports 20 different spatial covariances and models them directly, rather than using a precision matrix approximation to the MatÃ©rn spatial covariance as in \pkg{sdmTMB}. \pkg{spmodel} can also model areal data directly using neighborhood distance and autoregressive models rather than relying on the polygon centroid (as in \pkg{sdmTMB}). \pkg{spmodel} also provides experimental design tools (e.g., analysis of variance, contrasts), supports \pkg{sf} objects in modeling and prediction functions [@pebesma2018sf], has several specialized model diagnostics like leverage values and Cook's distances, and has analytic solutions for prediction standard errors. Other similarities and differences do exist between \pkg{sdmTMB} and \pkg{spmodel}, and both packages continue to evolve. Overall, we believe that these packages are complementary and enhance the suite of SPGLM tools accessible to practitioners.

The rest of this article is organized as follows. In Section$~$\ref{sec-spglm}, we provide some background for the SPGLM fitting and prediction routines in \pkg{spmodel}. In Section$~$\ref{sec-applications}, we provide several applications of \pkg{spmodel} to spatial binary, count, skewed and proportion data with both point-referenced and areal supports. And in Section$~$\ref{sec-discussion}, we end with a discussion synthesizing \pkg{spmodel}'s contributions to the analysis of SPGLMs in \proglang{R}.

# The spatial generalized linear model and marginalizatoin {#sec-spglm}

\pkg{spmodel} implements the novel methods described in @ver2024marginal to fit SPGLMs, which leverages the Laplace approximation and marginalizes over both the latent $\mathbf{w}$ and the fixed effects while accommodating spatial covariance. A beneficial aspect of this approach is that it formally maximizes a hierarchical GLM likelihood [@lee1996hierarchical; @wood2017generalized]. This makes likelihood-based statistics for model comparison like AIC [@akaike1974new], AICc [@hoeting2006model], BIC [@schwarz1978estimating], deviance [@mccullagh1989generalized], and likelihood ratio tests available. These types of statistics are not available for quasi-likelihood [@wedderburn1974quasi; @breslow1993approximate] or pseudo-likelihood approaches [@wolfinger1993generalized], which only specify the first two moments of a distribution. @ver2024marginal provides thorough details regarding the method and contextualizes its development which built upon similar methods [@evangelou2011estimation, @bonat2016practical]. Next, we describe a brief overview of the approach and how it can be used for parameter estimation, inference, and prediction.

## Formulating the hierarchical likelihood

We can write the SPGLM likelihood hierarchically as
\begin{equation}\label{eq-marginal}
  [\mathbf{y}|\mathbf{X}, \varphi, \boldsymbol{\theta}] = \int_{\mathbf{w}} \int_{\boldsymbol{\beta}} [\mathbf{y} | f^{-1}(\mathbf{w}), \varphi] [\mathbf{w} | \mathbf{X}, \boldsymbol{\theta}] d\boldsymbol{\beta} d\mathbf{w},
\end{equation}
where $[\mathbf{y} | f^{-1}(\mathbf{w}), \varphi]$ is the density for the appropriate response distribution of $\mathbf{y}$ (e.g., binomial, Poisson) given the latent $\mathbf{w}$ and dispersion parameter ($\varphi$), and $[\mathbf{w} | \mathbf{X}, \boldsymbol{\theta}]$ is the multivariate Gaussian density for $\mathbf{w}$ given the explanatory variables ($\mathbf{X}$), fixed effects ($\boldsymbol{\beta}$), and spatial covariance parameters ($\boldsymbol{\theta}$). The elements of $[\mathbf{y} | f^{-1}(\mathbf{w}), \varphi]$ are conditionally independent (given $\mathbf{w}$), but the elements of $[\mathbf{w} | \mathbf{X}, \boldsymbol{\theta}]$ share spatial covariance. Following @harville1977maximum, we can integrate $\boldsymbol{\beta}$ out of Equation$~$\ref{eq-spglm}, which yields
\begin{equation}\label{eq-marginal2}
  [\mathbf{y}|\mathbf{X}, \varphi, \boldsymbol{\theta}] = \int_{\mathbf{w}} [\mathbf{y} | f^{-1}(\mathbf{w}), \varphi] [\mathbf{w} | \mathbf{X}, \boldsymbol{\theta}] d\mathbf{w},
\end{equation}
where $[\mathbf{w} | \mathbf{X}, \boldsymbol{\theta}]$ is the restricted (i.e., residual) multivariate Gaussian density [@patterson1971recovery] for $\mathbf{w}$ given the explanatory variables and covariance parameters. Equation$~$\ref{eq-marginal2} can be synonymous written after profiling the overall variance out of $\boldsymbol{\Sigma}$, which reduces the dimension of $\boldsymbol{\theta}$ by one for optimization [@wolfinger1994computing]. The restricted multivariate Gaussian density is given by
\begin{equation}\label{eq-reml-def}
[\mathbf{w} | \mathbf{X}, \boldsymbol{\theta}] = \frac{\exp(-\frac{1}{2}(\mathbf{y} - \mathbf{X}\tilde{\boldsymbol{\beta}}) \boldsymbol{\Sigma}^{-1} (\mathbf{y} - \mathbf{X}\tilde{\boldsymbol{\beta}})^T)}{(2 \pi)^{(n - p)/2} |\boldsymbol{\Sigma}|^{1/2}|\mathbf{X}^T \boldsymbol{\Sigma}^{-1} \mathbf{X}|^{1/2}},
\end{equation}
where $\tilde{\boldsymbol{\beta}} = (\mathbf{X}^T \boldsymbol{\Sigma}^{-1} \mathbf{X})^{-1} \mathbf{X}^T \boldsymbol{\Sigma}^{-1} \mathbf{w}$ and $|\cdot|$ denotes the determinant. Next, let 
\begin{equation}\label{eq-marginal03}
  \ell_\mathbf{w} = \log([\mathbf{y} | f^{-1}(\mathbf{w}), \varphi] [\mathbf{w} | \mathbf{X}, \boldsymbol{\theta}])
\end{equation}
and rewrite Equation$~$\ref{eq-marginal2} as 
\begin{equation}\label{eq-marginal3}
  [\mathbf{y}|\mathbf{X}, \varphi, \boldsymbol{\theta}] = \int_{\mathbf{w}} \exp(\ell_\mathbf{w}) d\mathbf{w}.
\end{equation}
A second-order Taylor series expansion of $\ell_\mathbf{w}$ around $\hat{\mathbf{w}}$ yields
\begin{equation}\label{eq-marginal4}
  [\mathbf{y}|\mathbf{X}, \varphi, \boldsymbol{\theta}] \approx \int_{\mathbf{w}} \exp(\ell_{\hat{\mathbf{w}}} + \mathbf{g}^T(\mathbf{w} - \hat{\mathbf{w}}) + \frac{1}{2}(\mathbf{w} - \hat{\mathbf{w}})^T \mathbf{G} (\mathbf{w} - \hat{\mathbf{w}}))d\mathbf{w},
\end{equation}
where $\mathbf{g}$ and $\mathbf{G}$ are the gradient and Hessian, respectively, of $\ell_\mathbf{w}$ with respect to $\mathbf{w}$. If $\hat{\mathbf{w}}$ is a value for which $\mathbf{g} = \mathbf{0}$,
\begin{equation}\label{eq-marginal5}
  [\mathbf{y}|\mathbf{X}, \varphi, \boldsymbol{\theta}] \approx \exp(\ell_{\hat{\mathbf{w}}}) \int_{\mathbf{w}} \exp(-\frac{1}{2}(\mathbf{w} - \hat{\mathbf{w}})^T (-\mathbf{G}) (\mathbf{w} - \hat{\mathbf{w}}))d\mathbf{w}.
\end{equation}
The integral in Equation$~$\ref{eq-marginal5} can be solved by leveraging properties of the normalizing constant of a multivariate Gaussian distribution. Thus, rewriting $\exp(\ell_{\hat{\mathbf{w}}})$ yields
\begin{equation}\label{eq-marginal6}
  [\mathbf{y}|\mathbf{X}, \varphi, \boldsymbol{\theta}] \approx [\mathbf{y} | f^{-1}(\hat{\mathbf{w}}), \varphi] [\hat{\mathbf{w}} | \mathbf{X}, \boldsymbol{\theta}] (2 \pi)^{n/2}|-\mathbf{G}_{\hat{\mathbf{w}}}|^{-1/2}.
\end{equation}

Maximizing the natural logarithm of Equation$~$\ref{eq-marginal6} requires a doubly iterative process over $\boldsymbol{\theta}$ and $\varphi$ as well as $\mathbf{w}$, eventually yielding the the marginal restricted maximum likelihood estimators $\hat{\varphi}$ and $\hat{\boldsymbol{\theta}}$ and their corresponding values of $\hat{\mathbf{w}}$. Maximizing this log likelihood is a computationally expensive operation that involves repeatedly evaluating $\boldsymbol{\Sigma}^{-1}$, $\mathbf{g}$, and $\mathbf{G}$; see @ver2024marginal for more details and forms of $\mathbf{g}$ and $\mathbf{G}$ for various response distributions.

## Estimating fixed effects

Though the fixed effects are integrated out of the likelihood, we can still estimate them using generalized least squares (GLS) principles, a common practice for linear models estimated using restricted maximum likelihood methods. Had we observed $\mathbf{w}$, a GLS estimator for $\boldsymbol{\beta}$ is given by
\begin{equation}\label{eq-gls1}
  \hat{\boldsymbol{\beta}} = (\mathbf{X}^\top \boldsymbol{\Sigma}^{-1}\mathbf{X})^{-1}\mathbf{X}^\top \boldsymbol{\Sigma}^{-1}\mathbf{w} = \mathbf{B}\mathbf{w},
\end{equation}
where $\mathbf{B} = (\mathbf{X}^\top \boldsymbol{\Sigma}^{-1}\mathbf{X})^{-1}\mathbf{X}^\top \boldsymbol{\Sigma}^{-1}$. However, we only observe $\hat{\mathbf{w}}$, so it is reasonable to define $\hat{\boldsymbol{\beta}} = \mathbf{B}\hat{\mathbf{w}}$. Thus, to derive properties of $\hat{\boldsymbol{\beta}}$ like expectation and variance, we must derive these properties for $\hat{\mathbf{w}}$. To do so, we must condition on $\mathbf{w}$ as if it were observed and invoke properties of the laws of total expectation and variance. Because $\hat{\mathbf{w}}$ was optimized via the likelihood, we assume that given $\mathbf{w}$, $\hat{\mathbf{w}}$ has mean $\mathbf{w}$ and variance approximately equal to $-\mathbf{H}^{-1}$ (the inverse Hessian). It follows that $\text{E}(\hat{\mathbf{w}})$ is given by
\begin{equation}
  \text{E}(\hat{\mathbf{w}}) = \text{E}(\text{E}(\hat{\mathbf{w}} | \mathbf{w}))
   = \text{E}(\mathbf{w}) 
   = \mathbf{X}\boldsymbol{\beta}
\end{equation}
and $\text{Var}(\hat{\mathbf{w}})$ is given by
\begin{align}
  \text{Var}(\hat{\mathbf{w}}) & = \text{E}(\text{Var}(\hat{\mathbf{w}} | \mathbf{w})) + \text{Var}(\text{E}(\hat{\mathbf{w}} | \mathbf{w})) \\
  & = \text{E}(-\mathbf{H}^{-1}) + \text{Var}(\mathbf{w})\\
  & = -\mathbf{H}^{-1} + \boldsymbol{\Sigma}
\end{align}
Putting this all together, it follows that
\begin{equation}
  \text{E}(\hat{\boldsymbol{\beta}})  = \text{E}(\mathbf{B}\hat{\mathbf{w}}) 
  = \mathbf{B}\text{E}(\hat{\mathbf{w}}) =  (\mathbf{X}^\top \boldsymbol{\Sigma}^{-1}\mathbf{X})^{-1}(\mathbf{X}^\top \boldsymbol{\Sigma}^{-1} \mathbf{X})\boldsymbol{\beta} = \boldsymbol{\beta}
\end{equation}
and
\begin{align}
  \text{Var}(\hat{\boldsymbol{\beta}}) & = \text{Var}(\mathbf{B}\hat{\mathbf{w}}) \\
  & = \mathbf{B} \text{Var}(\hat{\mathbf{w}}) \mathbf{B}^\top\\
  & = \mathbf{B} (-\mathbf{H}^{-1} + \boldsymbol{\Sigma}) \mathbf{B}^\top \\
  & = \mathbf{B}-\mathbf{H}^{-1}\mathbf{B}^\top + \mathbf{B}\boldsymbol{\Sigma}\mathbf{B}^\top \\
  & = \mathbf{B}-\mathbf{H}^{-1}\mathbf{B}^\top + (\mathbf{X}^\top \boldsymbol{\Sigma}^{-1}\mathbf{X})^{-1}
\end{align}
In practice, $\text{Var}(\hat{\boldsymbol{\beta}})$ is estimated by evaluating $\boldsymbol{\Sigma}$ at $\hat{\boldsymbol{\theta}}$, the estimated covariance parameter vector.

These results are important because they justify closed-form solutions for $\hat{\boldsymbol{\beta}}$ and its associated variance. Closed-form solutions are useful because they bypass the need for computationally expensive sampling-based strategies to evaluate the mean and variance of $\hat{\boldsymbol{\beta}}$ -- a common technique for other approaches to SPGLMs like Bayesian MCMC. 

## Inspecting model diagnostics

Inspecting model diagnostics is an important step of the modeling process that can yield valuable insights into model behavior and unusual observations. @montgomery2021introduction contextualize three components of unusual observations: outliers, leverage, and influence. An observation is an outlier if it has an unusual response value relative to expectation. The response GLM residuals simply compare the observation to its fitted latent mean:
\begin{equation}
  \mathbf{r}_{r} = \mathbf{y} - f^{-1}(\hat{\mathbf{w}})
\end{equation}
Because observations often have a unique support in a GLM (e.g., only two possible response values for binary data) and the variance of an observation generally depends on its mean, response residuals lack some utility. Deviance residuals are a function of response residuals that are appropriately scaled to behave more like response residuals in a standard linear model. Deviance residuals are given by
\begin{equation}
  \mathbf{r}_{d} = sign(\mathbf{r}_{r})\sqrt{\mathbf{d}},
\end{equation}
where $\mathbf{d}$ is a vector of individual deviances. The sum of the squared deviance residuals equals the sum of $\mathbf{d}$. The sum of $\mathbf{d}$ is the deviance of the model fit, which quantifies twice the difference in log likelihoods between the a saturated model that fits every observation perfectly (i.e., $\mathbf{y} = f^{-1}(\hat{\mathbf{w}}_i)$ for all $i$) and the fitted model. Deviance is often used as a fit statistic; lower values of deviance imply a better model fit. Pearson and standardized residuals are other types of GLM residuals that involve some scaling of the response residuals; the Pearson residuals scale $\mathbf{r}_{r}$ by the squrae root of $\mathbf{V}$, while the standardized residuals scale the deviance residuals by $\frac{1}{\sqrt{(1 - \mathbf{L}_{ii})}}$, where $\mathbf{L}_{ii}$ is the $i$th diagonal element of the leverage matrix, which we discuss next.
An observation has high leverage if its combination of explanatory variables is far away from other observations. In a linear model, the leverage values are the diagonal of the leverage (i.e., projection, hat) matrix, $\mathbf{L} = \mathbf{X}(\mathbf{X}^\top \mathbf{X})^{-1}\mathbf{X}^\top$. In a GLM, the leverage matrix is given by
\begin{equation}
  \mathbf{L} = \mathbf{V}^{1/2} \mathbf{X} (\mathbf{X}^\top \mathbf{V} \mathbf{X}) \mathbf{X}^\top \mathbf{V}^{1/2},
\end{equation}
where $\mathbf{V}$ is a diagonal matrix with $i$th diagonal element equal to the variance of the response distribution evaluated at $f^{-1}(\mathbf{w}_i)$ [@faraway2016extending]. The matrix $\mathbf{V}$ is sometimes called the GLM weight matrix. The larger the $i$th diagonal element of the hat matrix, the more severe the leverage from the $i$th observation.
An observation is influential if it has a sizeable impact on model fit. Influence is measured using Cook's distance [@cook1979influential; @cook1982residuals], which is given for a GLM by
\begin{equation}
  \mathbf{c} = \mathbf{r}^2_{s} \frac{diag(\mathbf{L})}{\text{tr}(\mathbf{L})(\mathbf{1} - diag(\mathbf{L}))},
\end{equation}
where $\mathbf{r}^2_{s}$ are the standardized residuals and $diag(\mathbf{L})$ indicates the diagonal elements of the leverage matrix. The larger the $i$th diagonal element of the hat matrix, the more severe the influence from the $i$th observation.  @montgomery2021introduction provide guidance for interpreting these types of statistics, including cutoffs to consider when identifying unusual residual, leverage, or influence values.

In a linear model, the $R^2$ (R-squared) statistic quantifies the proportion of variability in the data captured by the explanatory variables and is calculated as one minus the ratio of the error sum of squares to the total sum of squares [@rencher2008linear]. In a GLM, there are many ways to define such a statistic [@smith2013comparison]. One such approach is to use one minus the deviance ratio:
\begin{equation}
  PR^2 = 1 - \frac{deviance_{fit}}{deviance_{null}},
\end{equation}
where $deviance_{fit}$ is the deviance of the fitted model (sometimes called the residual deviance) and $deviance_{null}$ is the deviance of the model taking $\mathbf{X} \equiv \mathbf{1}$, a column of all ones (i.e., an intercept-only model). In practice, $deviance_{null}$ is derived by computing $\hat{\mathbf{w}}$ when $\mathbf{X} \equiv \mathbf{1}$ given $\hat{\boldsymbol{\theta}}$ and $\hat{\varphi}$ from the fitted model. Like the standard $R^2$, this statistic attempts to capture variability (i.e., deviance) attributable to the explanatory variables. Because the $deviance_{null}$ denominator changes across fitted models (as the values of $\hat{\boldsymbol{\theta}}$ and $\hat{\varphi}$ change), this statistic should not be used as a model comparison tool. Instead, it should be used as an informative diagnostic tool unique to each model fit.

## Predicting at new locations

We may also predict values of the latent mean (on the link scale) at new locations by leveraging the spatial covariance between observed locations and new locations (spatial prediction is also called Kriging; see @cressie1990origins). Again suppose that we observed $\mathbf{w}$ and we want to make predictions at $\mathbf{u}$, a vector of latent means at the new locations that follows the same SPGLM from Equation~\ref{eq-spglm} with fixed effects design matrix, $\mathbf{X}_{\mathbf{u}}$. The vector $(\mathbf{w}, \mathbf{u})^\top$ has the following properties:
\begin{align}
  \text{E}(\mathbf{w}, \mathbf{u})^\top & = (\text{E}(\mathbf{w}), \text{E}(\mathbf{u}))^\top = (\mathbf{X}\boldsymbol{\beta}, \mathbf{X}_\mathbf{u}\boldsymbol{\beta})^\top \\
  \text{Var}(\mathbf{w}, \mathbf{u})^\top & = \begin{bmatrix} \text{Var}(\mathbf{w}, \mathbf{w}) & \text{Var}(\mathbf{w}, \mathbf{u}) \\ \text{Var}(\mathbf{u}, \mathbf{w}) & \text{Var}(\mathbf{u}, \mathbf{u}) \end{bmatrix} = \begin{bmatrix} \boldsymbol{\Sigma} & \boldsymbol{\Sigma}_{\mathbf{w}\mathbf{u}} \\ \boldsymbol{\Sigma}_{\mathbf{u}\mathbf{w}} & \boldsymbol{\Sigma}_{\mathbf{u}\mathbf{u}} \end{bmatrix}
\end{align}
Because we have observed $\mathbf{w}$, we may derive the conditional distribution of $\mathbf{u}|\mathbf{w}$, which has the following properties:
\begin{align}
  \text{E}(\mathbf{w} | \mathbf{u}) & = \mathbf{X}_{\mathbf{u}} \boldsymbol{\beta} + \boldsymbol{\Sigma}_{\mathbf{u}, \mathbf{w}}\boldsymbol{\Sigma}^{-1}(\mathbf{w} - \mathbf{X}\boldsymbol{\beta}) \\
  \text{E}(\mathbf{w} | \mathbf{u}) & = \boldsymbol{\Sigma}_{\mathbf{u}, \mathbf{u}} - \boldsymbol{\Sigma}_{\mathbf{u}, \mathbf{w}} \boldsymbol{\Sigma}^{-1} \boldsymbol{\Sigma}_{\mathbf{w}, \mathbf{u}}
\end{align}
@ver2024marginal show how these equations are adjusted to reflect uncertainty in both $\hat{\boldsymbol{\beta}}$ and $\hat{\mathbf{w}}$ while leveraging the laws of total expectation and variance yet again. They derive the predictor of $\mathbf{u}$, $\hat{\mathbf{u}}$, and its associated variance, given by:
\begin{align}
  \hat{\mathbf{u}} & = \mathbf{X}_{\mathbf{u}} \hat{\boldsymbol{\beta}} + \boldsymbol{\Sigma}_{\mathbf{u}, \mathbf{w}}\boldsymbol{\Sigma}^{-1}(\hat{\mathbf{w}} - \mathbf{X}\hat{\boldsymbol{\beta}}) \\
  \text{Var}(\hat{\mathbf{u}}) & = \boldsymbol{\Sigma}_{\mathbf{u}, \mathbf{u}} - \boldsymbol{\Sigma}_{\mathbf{u}, \mathbf{w}} \boldsymbol{\Sigma}^{-1} \boldsymbol{\Sigma}_{\mathbf{w}, \mathbf{u}} + \mathbf{K}(\mathbf{X}^\top \boldsymbol{\Sigma}^{-1}\mathbf{X})^{-1}\mathbf{K}^\top + \boldsymbol{\Lambda}(-\mathbf{H})^{-1}\boldsymbol{\Lambda}^\top,
\end{align}
where $\mathbf{K} = \mathbf{X}_{\mathbf{u}} - \boldsymbol{\Sigma}_{\mathbf{u}, \mathbf{w}} \boldsymbol{\Sigma}^{-1} \mathbf{X}$ and $\boldsymbol{\Lambda} = \mathbf{X}_{\mathbf{u}}\mathbf{B} + \boldsymbol{\Sigma}_{\mathbf{u}, \mathbf{w}}\boldsymbol{\Sigma}^{-1}(\mathbf{1} - \mathbf{X}\mathbf{B})$ for a vector of ones, $\mathbf{1}$.

As with $\hat{\boldsymbol{\beta}}$, in practice these covariance matrices are evaluated at $\hat{\boldsymbol{\theta}}$. Moreover, these closed-form solutions provided enhance computational efficiency and clarity of the predictor's behavior. 

# Modeling moose presence in Alaska, USA {#sec-applications}

The \code{moose} data in \pkg{spmodel} contain information on moose (Alces Alces) presence in the Togiak region of Alaska, USA.   \code{moose}is an \code{sf} object, a special data frame that is supplemented with spatial information using the \pkg{sf} package in \proglang{R} [@pebesma2018sf]. The first few rows of \code{moose} look like:

```{r}
head(moose)
```

There are five columns: \code{elev}, the numeric site elevation (meters); \code{strat} a stratification variable for sampling with two levels, \code{"L"} and \code{"M"}, which are categorized by landscape metrics at each site; \code{count}, the number of moose at each site; \code{presence}, a factor that indicates whether at least one moose was observed at each site (\code{0} implies no moose; \code{1} implies at least one moose); and \code{geometry}, the NAD83/Alaska Albers (EPSG: 3338) projected coordinate of each site (these data are point-referenced because each observation occurs at point coordinates and are represented by a \code{POINT} geometry. The \code{moose_preds} data in \pkg{spmodel} contain spatial locations at which predictions of moose presence are desired (and is also point-referenced). \code{moose_preds} is also an \code{sf} object with measurements for \code{elev} and \code{strat} and the same projection system. Figure$~$\ref{fig-moose-data} shows the \code{presence} variable in \code{moose} as well as the spatial locations of both \code{moose} and \code{moose_preds}. Moose are most commonly present in the southwestern and eastern parts of the domain and least commonly present in the northwest (Figure$~$\ref{fig-moose-data}). Next we show how to use \pkg{spmodel} to study the effect of elevation and strata on moose presence while accounting for spatial covariance and to make predictions of moose presence at new locations.

\begin{figure}
\centering
\includegraphics[width = 0.70\linewidth]{figures/figure-1.png}
\caption{Moose presence in Alaska. Circles represent moose presence or absence (based on color) and triangles represent locations at which moose presence probability predictions are desired.}
\label{fig-moose-data}
\end{figure}

## Model Fitting

SPGLMs in \pkg{spmodel} are fit using the \code{spglm()} function. The \code{spglm()} function requires four arguments: `formula`, the relationship between the response and explanatory variables; `family`, the response distribution assumed for the repsonse variable; `data`, the data frame that contains the variables in `formula`, and `spcov_type`, the type of spatial covariance. These first three arguments are the three required arguments to \code{glm()} for nonspatial GLMs. So, the transition from \code{glm()} to \code{spglm()}
simply requires one additional argument: \code{spcov_type}. When \code{data} is not an \code{sf} object, \code{spglm()} also requires the \code{xcoord} and \code{ycoord} arguments, which indicate the columns in \code{data} that represent the x- and y-coordinates, respectively (it is assumed these coordinates are already projected).

We use \code{spglm()} to fit a spatial logistic regression model quantifying the effect of elevation and strata on moose presence:
```{r}
spbin <- spglm(
  formula = presence ~ elev + strat,
  family = binomial,
  data = moose,
  spcov_type = "exponential"
)
```

The \code{summary()} function returns a model summary that returns relevant information like the function call, deviance residuals, a coefficients table of fixed effects, the pseudo R-squared, spatial covariance parameter coefficient estimates, and the GLM dispersion parameter (fixed at one in logistic regression):
```{r}
summary(spbin)
```

Based on this model, there is some evidence that elevation is associated with higher probabilities of moose presence ($p$-value $\approx$ 0.087) but strong evidence that moose are more prevalent in the \code{"M"} strata than the \code{"L"} strata ($p$-value < 0.001). The fixed effects coefficients table from \code{summary()} is often of primary practical interest, but it is not easily usable when printed directly to the \proglang{R} console. The \code{tidy()} function tidies this table, turning it into a data frame (i.e., a tibble) with standard column names:
```{r}
tidy(spbin, conf.int = TRUE)
```

## Model Comparison

The strength of spatial covarinace in the data affects how beneficial a SPGLM is relative to a GLM. When the spatial covariance is strong, the SPGLM should notably outperform the GLM. When the spatial covariance is weak, the SPGLM and GLM should perform similarly. We can quantify the benefits of incorporating spatial covariance for a particular data set by comparing the fit of a SPGLM to a GLM. We can fit a GLM in \code{spmodel} by specifying \code{spcov_type = "none"}: 

```{r}
bin <- spglm(
  formula = presence ~ elev + strat,
  family = binomial,
  data = moose,
  spcov_type = "none"
)
```

While the \code{spglm()} approach evaluates the HGLMM likelhood with $\sigma^2_{de} = 0$ and $\sigma^2_{ie} \approx 0$ instead of just the GLM likelihood, the parameter estimates and their standard errors are the same:

```{r}
bin_glm <- glm(
  formula = presence ~ elev + strat,
  family = binomial,
  data = moose,
)
round(coef(bin), digits = 4)
round(coef(bin_glm), digits = 4)
round(sqrt(diag(vcov(bin))), digits = 4)
round(sqrt(diag(vcov(bin_glm))), digits = 4)
```

However, using \code{spglm()} instead of \code{glm()} ensures that \pkg{spmodel} helper functions are available and that each of the \code{spglm()} models uses the same likelihood:
```{r}
glance(spbin)
glance(bin)
```

The likelihood-based statistics AIC, AICc, BIC, and deviance are much lower for the SPGLM, indicating a better fit relative to the GLM. We may also perform a likelihood ratio test (LRT) between the two models, as the GLM is a special case of the SPGLM (i.e., is nested within the SPGLM):
```{r}
tidy(anova(spbin, bin))
```

The LRT test statistic is $\approx$ 31.5 with three degrees of freedom (the difference in covariance parameters), yielding a $p$-value $< 0.001$ that indicates preference for the full model (SPGLM) relative to the reduced model (GLM).

An alternative approach to model comparison is to use a cross-validation procedure [@james2013introduction]. The \code{loocv()} function performs leave-one-out cross validation, comparing the predicted mean (on the response scale) to the observed response variable for each hold-out observation, recomputing estimates of $\boldsymbol{\beta}$ each time. Then, statistics like bias, mean-squared-prediction error (MSPE), and the square root of MSPE (RMSPE) can be used to evaluate models:

```{r}
loocv(spbin)
loocv(bin)
```

Both models have negligible bias, but the SPGLM has much lower MSPE and RMSPE than the GLM, indicating the SPGLM predictions are far more efficient. Three separate metrics (likelihood-based statistics, likelihood-ratio test, and leave-one-out cross validation) prefer the SPGLM to the GLM.

We can compare two SPGLMs with different spatial covariance functions using likelihood-based statistics and leave-one-out cross validation, but we can't use the LRT because generally, the spatial covariance functions aren't nested:
```{r}
spbin2 <- update(spbin, spcov_type = "spherical")
glances(spbin, spbin2)
loocv(spbin)
loocv(spbin2)
```

The \code{"exponential"} spatial covariance (\code{spbin}) has a slightly lower deviance but slightly higher AIC, AICc, and BIC than 
the \code{"spherical"} spatial covariance (\code{spbin2}). Both spatial covariance functions nearly identical leave-one-out cross validation metrics. For practical purposes, these models fit quite similarly.

## Model Diagnostics

\code{spmodel} provides a suite of tools for model diagnostics. The \code{augment()} function augments the model data with diagnostics:
```{r}
augment(spbin)
```

The fitted values (\code{.fitted}) can be returned on either the link ($\hat{\mathbf{w}}$) or response ($f^{-1}\hat{\mathbf{w}}$) scale and the residuals (\code{.resid}) can deviance, pearson, or response residuals. The defaults are the link scale and deviance residuals, respectively. Also returned by \code{augment()} are the leverage (\code{.hat}), Cook's distance (\code{.cooksd}), and standardized residuals \code{.std.resid}. A benefit of using \code{augment()} when \code{data} is an \code{sf} object is that the output is also an \code{sf} object, which makes it straightforward to create spatial diagnostic plots (Figure$~$\ref{fig-sp-diagnostic}). Standard \proglang{R} helpers (e.g., \code{fitted()}, \code{residuals()}) are available to alternatively extract model diagnostics from the model object.

\begin{figure}
\centering
\includegraphics[width = 1\linewidth]{figures/figure-2.png}
\caption{Spatial logistic regression model diagnostics from [augment]{.fct}. The leverage (i.e., hat) values (left) and standardized residuals (right).}
\label{fig-sp-diagnostic}
\end{figure}

The \code{plot()} function can also be used to return similar diagnostics as from \code{lm()} and \code{glm()} with additional tools for spatial covariance. For example, we can inspect Cook's distance values and the empirical spatial covariance as a function (Figure$~$\ref{fig-sp-diagnostic2}) with 
```{r, eval = FALSE}
plot(spbin, which = c(4, 7))
```

\begin{figure}
\centering
\includegraphics[width = 1\linewidth]{figures/figure-3.png}
\caption{Spatial logistic regression model diagnostics from [plot]{.fct}. The Cook's distance values (left) and the fitted spatial covariance as a function of distance (right).}
\label{fig-sp-diagnostic2}
\end{figure}

The \code{varcomp()} function partitions model variability into several different components:
```{r}
varcomp(spbin)
```

The pseudo R-squared ($PR^2$), the proportion of variability attributable to the explanatory variables, is reported in the first row. The remaining variability ($1 - PR^2$) is allocated proportionally to \code{de} and \code{ie} according to $\sigma^2_{de}$ and $\sigma^2_{ie}$. This variability partitioning is a useful that helps quantify how much the explanatory variables, residual spatial variance, and residual nonspatial variance contribute to model fit, but as with $PR^2$, should not be used as a model comparison tool.

## Prediction

We can predict the probability of moose presence using \code{predict()}:
```{r}
predict(spbin, newdata = moose_preds)[1:5]
```

By default, predictions are returned on the link scale, but this can be changed to the response scale via \code{type}:
```{r}
predict(spbin, newdata = moose_preds, type = "response")[1:5]
```

Predictions on the response scale are visualized alongside the fitted values ($f^{-1}\hat{\mathbf{w}}$) in Figure$~$\ref{fig-moose-fit}.

\begin{figure}
\centering
\includegraphics[width = 0.70\linewidth]{figures/figure-4.png}
\caption{Moose presence probability fitted values and predictions. Fitted values are represeneted by circles and predictions by triangles.}
\label{fig-moose-fit}
\end{figure}

Prediction intervals for the probability of moose presence (on the link scale) are returned via \code{interval}
```{r}
predict(spbin, newdata = moose_preds, interval = "prediction")[1:5, ]
```

We can alternatively use \code{augment()} to augment the prediction data with predictions. Arguments to \code{predict()} can also be passed to \code{augment()}:
```{r}
augment(spbin, newdata = moose_preds, interval = "prediction")
```

By using \code{augment()} when \code{newdata} is an \code{sf} object, predictions and their corresponding uncertainties are readily available for spatial mapping (Figure$~$\ref{fig-moose-int}).

\begin{figure}
\centering
\includegraphics[width = 1\linewidth]{figures/figure-5.png}
\caption{Moose presence probability prediction intervals. 95\% prediction interval lower bound (left) and 95\% prediction interval upper bound (right).}
\label{fig-moose-int}
\end{figure}


# Additional applications {#sec-applications2}

Throughout the remainder of this section, we briefly highlight some additional \pkg{spmodel} capabilities for SPGLMs. In Section$~$\ref{sec-moose-count}, we fit Poisson and negative binomial models with and without geometric anisotropy for the point-referenced moose count data. In Section$~$\ref{sec-seal}, we fit a binomial model to the areal seal trend data with a nonspatial random effect. In Section$~$\ref{sec-texas}, we fit beta models to Texas voter turnout data. We explore how the Texas data can be treated as point-referenced or areal and compare the two spatial covariance structures empirically. We also highlight how the maximum likelihood estimation method is useful when comparing two models with different explanatory variables. Finally, in Section$~$\ref{sec-lake}, we fit a Gamma model to the point-referenced lake conductivity data. We show how to perform a spatial analysis of variance (ANOVA) and leverage modeling functions from other \proglang{R} packages like \pkg{emmeans} and \pkg{car}.

## Modeling moose counts in Alaska, USA {#sec-moose-count}

In addition to moose presence, moose counts are also recorded in `moose` (Figure$~$\ref{fig-moose-data-count}.  The Poisson and negative binomial response distributions can be used to model SPGLMs for count data. Using a Gaussian spatial covariance function, we may fit both a Poisson and negative binomial SPGLM changing the `family` argument:

```{r}
sppois <- spglm(
  formula = count ~ elev + strat,
  family = poisson,
  data = moose,
  spcov_type = "gaussian"
)
spnb <- update(sppois, family = nbinomial)
```

\begin{figure}
\centering
\includegraphics[width = 0.70\linewidth]{figures/figure-6.png}
\caption{Moose counts in Alaska. Circles represent moose counts (based on color) and triangles represent locations at which mean count predictions are desired.}
\label{fig-moose-data-count}
\end{figure}

Because the Poisson and negative binomial distributions have the same support (nonnegative integers), we can compare them using  AIC, AICc, or BIC:
```{r}
BIC(sppois, spnb)
```

Implicit in our spatial covariance functions thus far has been an assumption of geometric isotropy. A spatial covariance function is geometrically isotropic if it decays with distance at the same rate in all directions (Figure$~$\ref{fig-tropy}; left). A spatial covariance is geometrically isotropic if it decays with distance at different rates in different directions (Figure$~$\ref{fig-tropy}; right). Geometric anisotropy is formally incorporated by rotating and scaling original coordinates, yielding transformed coordinates that are geometrically isotropic:
\begin{equation}
  \begin{bmatrix}
    x^* \\
    y^*
  \end{bmatrix} = 
  \begin{bmatrix}
    1 & 0 \\
    0 & 1 / \omega
  \end{bmatrix}
  \begin{bmatrix}
    \cos(\alpha) & \sin(\alpha) \\
    -\sin(\alpha) & \cos(\alpha)
  \end{bmatrix}  
  \begin{bmatrix}
    x \\
    y
  \end{bmatrix}.
\end{equation} 
The parameter $\alpha$ controls the rotation angle and the parameter $\omega$ controls the scaling...
Then using these transformed coordinates, the partial sill ($\sigma^2_{de}$), nugget ($\sigma^2_{ie}$), and range ($\phi$) parameters are estimated. 
```{r}
sppois_anis <- update(sppois, anisotropy = TRUE)
spnb_anis <- update(spnb, anisotropy = TRUE)
```

According to BIC, the spatial negative binomial model performs best. This model simultaneously accounts for anisotropy and overdispersion. The spatial correlation is strongest in a northwest-southeast direction and weakest in the northeast-southwest direction (Figure$~$\ref{fig-tropy}), which is intuitive given the similar patterns in moose counts from Figure$~$\ref{fig-moose-data-count}.
```{r}
BIC(sppois, spnb, sppois_anis, spnb_anis)
```

The `plot()` function can be used to visualize the anisotropy  (Figure$~$\ref{fig-tropy}):
```{r, eval = FALSE}
plot(spnb, which = 8)
plot(spnb_anis, which = 8)
```

\begin{figure}[h]
\centering
\includegraphics[width = 1\linewidth]{figures/figure-7.png}
\caption{Level curves of equal correlation for the negative binomial moose count models. The ellipse is centered at zero distance in the x-direction and y-direction, and points along the ellipse have equal levels of correlation.  In the isotropic level curve (left), spatial covariance decays equally in all directions. In the anistropic level curve (right), spatial covariance decays fastest in the northeast-southwest direction and slowest in the northwest-southeast direction (this pattern can be seen in the observed counts).}
\label{fig-tropy}
\end{figure}

## Modeling lake conductivity in Southwest, USA {#sec-lake}

The \code{lake} data in \code{spmodel} contains climate and chemical data for several lakes in four southwestern states in the United States: Arizona, Colorado, Nevada, and Utah. We desire an SPGLM that characterizes the effect of temperature, state, and lake origin (whether the lake is naturally occurring or human made) on lake conductivity. Conductivity is a measure of dissolved ions (measured here in water), which is important for various physical, chemical, and biological processes. Chemical data is often heavily right-skewed, so we model it using an SPGLM assuming a Gamma distribution for the response. The \code{log_cond} variable in \code{lake} is the logarithm of conductivity, and we can dynamically exponentiate within \code{formula} so that it is on the original scale:
```{r}
spgam <- spglm(
  formula = exp(log_cond) ~ temp + state + temp:state + origin, 
  family = "Gamma",
  data = lake,
  spcov_type = "cauchy",
  partition_factor = ~ year
)
```

We model conductivity as a function of temperature, state, and lake origin, and we allow the effect of temperature to vary by state (\code{temp:state}). The partition factor restricts spatial covariance to apply only for two observations sampled during the same year. Data were collected in 2012 and 2017, so the \code{year} partition factor assumes independence between observations in 2012 and 2017. While we used the partition factor here illustratively, more generally, the utility of partition factors can be highly context dependent.

When categorical variables have more than two levels, the default reference group contrasts are not well-suited to assess the variable's overall significance:
```{r}
summary(spgam)
```

A more effective approach is to use an analysis of variance (ANOVA), which is well-suited to asses the overall significance of each variable:
```{r}
anova(spgam)
```

The main effect for temperature and the temperature by state interaction are highly significant ($p$-value < 0.001), while the main effects for state and lake origin are not significant. The ANOVA table can be tidied using \code{tidy()}.

Variance inflation factors assess the degree to which standard errors $\hat{\boldsymbol{\beta}}$ are inflated due to covariance among the columns of $\mathbf{X}$. Generalized variance inflation factors can capture the variance inflation for subsets of $\mathbf{X}$ that may include categorical variables with more than two levels [@fox1992generalized]:

```{r}
library(car)
vif(spgam)
```

The GVIF$^{1/2df}$ values for \code{temp}, \code{state}, and \code{temp:state} are just greater than two, which suggests moderate multicollinearity for these terms -- unsurprising given the \code{temp:state} interaction in the model. The GVIF$^{1/2df}$ for \code{origin} is close to one, which suggests little to no multicollinearity for this term.

Because of the interaction between \code{temp} and \code{state}, contrasts that assess mean differences among states should condition upon a specific temperature value. By default, \pkg{emmeans} uses the mean temperature value to assess contrasts:
```{r}
library(emmeans)
pairs(emmeans(spgam, ~ state | temp))
```

Again because of the interaction between \code{temp} and \code{state}, we should assess temperature trends separately for each state:
```{r}
emtrends(spgam, ~ state, var = "temp")
```

## Modeling harbor seal trends in Alaska, USA {#sec-seal}

The \code{seal} data in \pkg{spmodel} contains harbor seal abundance trends for two different harbor seal stocks (genetically distinct populations). While the \code{moose} and \code{lake} data were point-referenced, the \code{seal} data are areal. Each polygon in the \code{seal} data represents a distinct harbor seal haulout location (Figure$~$\ref{fig-seal}). A haulout location is a spot on coastal rocks that harbor seals go to rest, molt, and give birth, among other tasks.

\begin{figure}
\centering
\includegraphics[width = 1\linewidth]{figures/figure-8.png}
\caption{Seal trend distribution in Alaska. Observed and missing seal polygons by stock (left) and observed log seal trends (right).}
\label{fig-seal}
\end{figure}

For each polygon, a Poisson regression was used to quantify the mean trend in abundance over approximately 30 years. If the logarithm of seal abundance (\code{log_trend}) is negative (positive), it means abundance is decreasing (increasing). We use a binomial SPGLM to quantify how likely it is for abundance trends to be decreasing:
```{r}
is_decreasing <- seal$log_trend < 0
spbin <- spgautor(
  formula = is_decreasing ~ 1,
  family = binomial,
  data = seal,
  spcov_type = "car",
  random = ~ stock
)
```

To model spatial dependence, we used a conditional autoregressive function. Conditional and simultaneous autoregressive functions characterize spatial distance through neighborhood relationships and have \code{spcov_type} values of \code{"car"} and \code{"sar"}, respectively. By default, Queen's distance is used to determine whether two sites are neighbors, though custom neighborhood matrices are passed via \code{W}. Row standardization is also assumed by default, though this can be changed via \code{row_st}. Using \code{random}, we also specified a nonspatial random effect for seal stock. The \code{random} argument uses similar syntax as \pkg{lme4} [@bates2015lme4] and \pkg{nlme} [@pinheiro2006mixed] to specify nonspatial random effects.

Tidying the model reveals the mean probability that trends are decreasing is between -0.979 and 1.66 (on the logit scale):
```{r}
tidy(spbin, conf.int = TRUE)
```

Back-transforming this interval to the probability scale yields:
```{r}
emmeans(spbin, ~ 1, type = "response")
```

The \code{SE} column is the standard error on the response scale obtained from the delta method [@oehlert1992note].

For areal data, the prediction locations must be specified at the time of model fitting, as they affect the spatial covariance function's neighborhood structure. Prediction locations whose response values have an \code{NA} (i.e., missing) value are converted into a \code{newdata} object that is stored in the model output. For example, rows one and nine are locations without seal trends, meaning they are not used in model fitting but are desired for prediction:
```{r}
seal
```

Then, \code{predict()} can be called without having to specify \code{newdata}:

```{r}
predict(spbin, type = "response", interval = "prediction")[1:5, ]
```

We could have alternatively used a (geostatistical) SPGLM via \code{spglm()}. When areal data are used with \code{spglm()}, the centroids of each polygon are used as the point-referenced coordinates. We further explore comparisons between point-referenced and aeral data next.

## Modeling voter turnout in Texas, USA {#sec-texas}

\begin{figure}
\centering
\includegraphics[width = 0.70\linewidth]{figures/figure-10.png}
\caption{Proportion of voter turnout in Texas for the 1980 presidential election. Circles represent voter turnout (based on color) and triangles represent locations at which voter turnout predictions are desired.}
\label{fig-texas}
\end{figure}

The \code{texas} data in \pkg{spmodel} contains voter turnout data for Texas counties in the 1980 United States Presidential Election [@bivand2024spdata]. The data are point-referenced, with polygon centroids representing the spatial location of each county (Figure$~$\ref{fig-texas}). Beta regression is a GLM used to model rate and proportion data in (0, 1) [@ferrari2004beta, @cribari2010beta]. We model voter turnout rates as a function of mean log income of county residents using an SPGLM assuming a beta distributed response variable:
```{r}
spbeta_geo <- spglm(
  formula = turnout ~ log_income,
  family = "beta", 
  data = texas,
  spcov_type = "matern"
)
```

Alternatively, we could use an autoregressive model to fit the model, constructing a neighborhood matrix by assuming centroids within \code{cutoff} of one another are neighbors:
```{r}
spbeta_auto <- spgautor(
  formula = turnout ~ log_income,
  family = "beta", 
  data = texas,
  spcov_type = "car",
  cutoff = 1e5
)
```

According to AIC, the SPGLM for point-referenced data is preferred:
```{r}
AIC(spbeta_geo, spbeta_auto)
```

The default estimation method in \pkg{spmodel} is restricted maximum likelihood (REML). One drawback of REML is that likelihood-based statistics are only valid for model comparison when the models have the same explanatory variable and fixed effect structure. This is because the error contrasts used to construct the REML likelihood change based on $\mathbf{X}$ and $\boldsymbol{\beta}$. An alternative is to use maximum likelihood, which can use likelihood-based statistics to compare models with different explanatory variable and fixed effect structures. While we could assess the significance of log turnout with the \code{spbeta_geo} model fit with REML (e.g., via \code{tidy()}), an alternative approach is to use a likelihood ratio test as long as the two models are nested. We refit the point-referenced model using maximum likelihood and compare it to a similar model without log income using the likelihood ratio test, accessible via \code{anova()} when providing two models:
```{r}
spbeta_full_ml <- update(spbeta_geo, estmethod = "ml")
spbeta_red_ml <- update(spbeta_full_ml, formula = turnout ~ 1)
anova(spbeta_full_ml, spbeta_red_ml)
```

The likelihood ratio test suggests that log income is significantly related to voter turnout. The \code{anova()} output can also be tidied using \code{tidy()}.

SAY SOMETHING ABOUT PREDICT.

# Discussion {#sec-discussion}

SPGLMs are fit in \pkg{spmodel} using a novel application of the Laplace approximation that marginalizes over the latent (i.e., unobserved) mean, $\mathbf{w}$, and the fixed effects, $\boldsymbol{\beta}$. The approach is quite flexible and accommodates any general response distribution and covariance structure.  \pkg{spmodel}'s \code{spglm()} and \code{spgautor()} functions are similar in structure and syntax as base \proglang{R}'s \code{glm()} function, easing the transition for practitioners from GLMs to SPGLMs. These functions support six response distributions for binary, count, and skewed data and support 20 spatial covariance functions. \pkg{spmodel} provides several additional features that are not covered here, including fitting multiple models simultaneously, fixing spatial covariance parameters at known values, fitting models to large non-Gaussian data having thousands of observations via spatial indexing [@ver2023indexing], incorporating spatial dependence in machine learning (e.g., random forests; @breiman2001random), simulating spatially dependent data (e.g., \code{spbinom()}, \code{sprpois()}, etc.), and more. Further details are provided by [https://CRAN.R-project.org/package=spmodel](https://CRAN.R-project.org/package=spmodel) and links therein.

# Computational details {.unnumbered}

The results in this paper were obtained using [R]{.proglang} 4.4.0 with the
\pkg{spmodel} 0.9.0 package. Figures were created using the [ggplot2]{.pkg} 3.5.1 package [@wickham2016ggplot2] and base [R]{.proglang}.

# Data and code availability {.unnumbered}

All writing and code associated with this manuscript is available for viewing and download on GitHub at [https://github.com/USEPA/spmodel.glm.manuscript](https://github.com/USEPA/spmodel.glm.manuscript). All data used are part of the \pkg{spmodel} [R]{.proglang} package available for download from CRAN at [https://CRAN.R-project.org/package=spmodel](https://CRAN.R-project.org/package=spmodel). 


# Acknowledgments {.unnumbered}

We would like to thank initial reviewers and editors for feedback that has greatly improved the manuscript.

The views expressed in this manuscript are those of the authors and do not necessarily represent the views or policies of the U.S. Environmental Protection Agency or the National Oceanic and Atmospheric Administration. Any mention of trade names, products, or services does not imply
an endorsement by the U.S. government, the U.S. Environmental Protection Agency, or the National Oceanic and Atmospheric
Administration. The U.S. Environmental Protection Agency and the National Oceanic and Atmospheric Administration do not endorse
any commercial products, services or enterprises.

\bibliography{references.bib}
